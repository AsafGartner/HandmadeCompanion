---
title: "Initializing DirectSound"
videoId: qGC3xiliJW8
markers:
    "1:02:05": "Start of Q&A"
    "1:04:05": "Fixing WaveFormat order"
    "1:06:07": "Do you use data-structures like linked-list, binary trees..?"
    "1:06:34": "Can you explain again why you need two buffers instead of just doing everything in one?"
    "1:09:23": "Are there any case we'd want more than two [audio] channels?"
    "1:11:05": "If the framerate would ever drop, can there be audio dropouts?"
    "1:13:41": "The nBlockAlign and nAverageBytesPerSecond are redundant."
    "1:14:57": "On Linux will we be doing ALSA or higher level like PulseAudio/Jack?"
    "1:16:00": "What newer sound API would you recommend instead of old DirectSound?"
    "1:16:46": "The two second buffer doesn't sound acceptable / not-noticeable if you're playing music."
    "1:17:27": "Have or do you work in the industry?"
    "1:17:54": "Have you thought about guest programmers tagging in to teach things like linux or whatever topic is their expertise?"
    "1:18:35": "VirtualAlloc: MEM_COMMIT to MEM_RESERVE|MEM_COMMIT"
    "1:20:23": "About game development as a career field"
    "1:22:57": "Will you show us how to use bone animations or will you use spritesheets?"
    "1:24:15": "More on our usage of DirectSound (Not a buffer)"
    "1:25:33": "About game programming optimisation"
    "1:27:56": "Why don't we use the second buffer to grab the handle instead of creating something just to grab a handle?"
    "1:29:26": "Isn't this learning how to carve stone with chisel instead of using modern machinery?"
---